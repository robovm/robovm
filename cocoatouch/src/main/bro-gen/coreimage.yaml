package: org.robovm.apple.coreimage
include: [coregraphics.yaml, foundation.yaml, opengles.yaml]
library: CoreImage
framework: CoreImage
clang_args: ['-x', 'objective-c']
headers:
    - /System/Library/Frameworks/CoreImage.framework/Headers/CoreImage.h
typedefs: {}
enums:

classes:

    CIColor:
        methods:
            '+colorWithCGColor:':
                exclude: true
            '+color.*':
                visibility: protected
                return_type: "@Pointer long"
            '-(alpha|blue|colorSpace|green|numberOfComponents|red|stringRepresentation)':
                property: true
            '-components':
                visibility: protected
    CIContext:
        methods:
            '+context.*':
                visibility: protected
                return_type: "@Pointer long"
            '-(inputImageMaximumSize|outputImageMaximumSize)':
                property: true
            '-drawImage.*':
                name: drawImage
            # Skip methods that renders to CVBuffers for now until we have CoreVideo support
            '-render:toCVPixelBuffer:.*':
                exclude: true
            '-render.*':
                name: render
            '-createCGImage.*':
                name: createCGImage
            '-createCGLayer.*':
                name: createCGLayer
    CIDetector:
        methods:
            '+detectorOfType:context:options:':
                visibility: protected
                return_type: "@Pointer long"
            '-featuresInImage.*':
                name: findFeatures
                return_type: "NSArray<CIFeature>"
    CIFaceFeature: {}
    CIFeature: {}
    CIFilter:
        skip_def_constructor: true
        methods:
            '+filterWithName:':
                name: getFilter
            '+serializedXMPFromFilters:inputImageExtent:':
                name: serializeToXMP
                parameters:
                    filters:
                        type: "NSArray<CIFilter>"
            '+filterArrayFromSerializedXMP:inputImageExtent:error:':
                name: deserializeFromXMP
                return_type: "NSArray<CIFilter>"
            '+filterNames.*':
                name: getFilterNames
                return_type: "NSArray<NSString>"
                parameters:
                    categories:
                        type: "NSArray<NSString>"
            '-(name|inputKeys|outputKeys|attributes)':
                property: true
    CIImage:
        methods:
            '+imageWith.*':
                exclude: true
            '+emptyImage':
                name: getEmptyImage
            '-(extent|properties)':
                property: true
            '-autoAdjustmentFilters.*':
                name: getAutoAdjustmentFilters
                return_type: "NSArray<CIFilter>"
            '-regionOfInterestForImage:inRect:':
                name: getRegionOfInterest
            '-image(By[^:]*).*':
                name: "createImage#{g[0]}"
            # Skip constructors that take a CVBuffer for now until we have CoreVideo support
            '-initWithCVPixelBuffer:.*':
                exclude: true

    CIVector:
        methods:
            '+vectorWith.*':
                exclude: true
            '-(X|Y|Z|W|count|stringRepresentation|CGAffineTransformValue|CGPointValue|CGRectValue)':
                property: true
            '-valueAtIndex:':
                name: getValueAtIndex
            '-initWithValues:count:':
                constructor: false

protocols:

functions:

    # Make sure we don't miss any functions if new ones are introduced in a later version
    (CI.*):
        class: CoreImage
        name: "Function__#{g[0]}"

values:

    kCIContext(.*):
        class: CIContext
        name: "Key#{g[0]}"
        type: NSString

    CIDetector(Accuracy|Tracking|MinFeatureSize):
        class: CIDetector
        name: "ConfigKey#{g[0]}"
        type: NSString
    CIDetector(Type.*):
        class: CIDetector
        name: "#{g[0]}"
    CIDetector(Accuracy.+):
        class: CIDetector
        name: "#{g[0]}"
        type: NSString
    CIDetector(ImageOrientation|EyeBlink|Smile):
        class: CIDetector
        name: "FeatureKey#{g[0]}"
        type: NSString

    CIFeature(TypeFace):
        class: CIFeature
        name: "#{g[0]}"

    kCI(Attribute.*):
        class: CIFilter
        name: "#{g[0]}"
        type: NSString
        readonly: true
    kCI(Category.*):
        class: CIFilter
        name: "#{g[0]}"
        type: NSString
        readonly: true
    kCI(Input.*)Key:
        class: CIFilter
        name: "Parameter#{g[0]}"
        type: NSString
        readonly: true
    kCI(Output.*)Key:
        class: CIFilter
        name: "Parameter#{g[0]}"
        type: NSString
        readonly: true

    kCI(Format.*):
        class: CIImage
        name: "#{g[0]}"
        readonly: true
    kCIImage(AutoAdjust.*):
        class: CIImage
        name: "#{g[0]}"
        type: NSString
        readonly: true
    kCIImage(.*):
        class: CIImage
        name: "Key#{g[0]}"
        type: NSString
        readonly: true

    # Not available on iOS
    kCIApplyOption.*:
        exclude: true
    kCIUI.*:
        exclude: true

    # Make sure we don't miss any values if new ones are introduced in a later version
    (k?CI.*):
        class: CoreImage
        name: "Value__#{g[0]}"

constants:

    # Make sure we don't miss any constants if new ones are introduced in a later version
    (k?CI.*):
        class: CoreImage
        name: "Constant__#{g[0]}"
